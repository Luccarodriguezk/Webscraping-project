{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg77TDsq7HalAi5XQ24PwU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luccarodriguezk/Webscraping-project/blob/main/Web_scraping_project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oUZmu3B0ssvP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://finance.yahoo.com/quote/AAPL/'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser') #creates a beautifulsoup object, a parser (data structure) with the html content\n",
        "results = soup.find('Volume')\n"
      ],
      "metadata": {
        "id": "DO8vZSH92WkG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_title = soup.title.string\n",
        "print(f\"Page Title: {page_title}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vR2V5Ua3jZP",
        "outputId": "1750cf11-9a6d-46fd-85b5-c89f3ae3d0d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page Title: Apple Inc. (AAPL) Stock Price, News, Quote & History - Yahoo Finance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headlines = soup.find_all('h2', class_='headline')\n",
        "print(\"\\nHeadlines:\")\n",
        "for headline in headlines:\n",
        "    print(headline.text.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb-e-Aio3rJ4",
        "outputId": "9d0c18c9-7f33-4164-ce0b-31dc221d74be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Headlines:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_stock_volume(ticker):\n",
        "    # Step 1: Set up the URL and send a GET request\n",
        "    url = f\"https://finance.yahoo.com/quote/{ticker}/\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Step 2: Create a BeautifulSoup object to parse the HTML\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Step 3: Find the volume data\n",
        "    volume_element = soup.find('fin-streamer', {'data-test': 'TD_VOLUME-value'})\n",
        "\n",
        "    # Step 4: Extract and process the volume data\n",
        "    if volume_element:\n",
        "        volume_text = volume_element.text.strip()\n",
        "        volume = int(re.sub(r'[^\\d]', '', volume_text))\n",
        "        return volume\n",
        "    else:\n",
        "        return \"Volume data not found\"\n",
        "\n",
        "# Step 5: Use the function to get AAPL stock volume\n",
        "aapl_volume = scrape_stock_volume('AAPL')\n",
        "print(f\"AAPL Stock Volume: {aapl_volume}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0G1zfW845gr",
        "outputId": "acb8388d-89c9-484c-db02-211d382bbfa3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAPL Stock Volume: Volume data not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_stock_volume(ticker):\n",
        "    url = f\"https://finance.yahoo.com/quote/{ticker}\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Look for the script tag containing the stock data\n",
        "        script = soup.find('script', text=re.compile('root.App.main'))\n",
        "\n",
        "        if script:\n",
        "            json_text = re.search(r'root.App.main\\s*=\\s*({.*?});', script.string, re.DOTALL).group(1)\n",
        "            data = json.loads(json_text)\n",
        "\n",
        "            # Navigate through the JSON structure to find the volume\n",
        "            try:\n",
        "                volume = data['context']['dispatcher']['stores']['QuoteSummaryStore']['summaryDetail']['volume']['raw']\n",
        "                return int(volume)\n",
        "            except KeyError:\n",
        "                return \"Volume data not found in JSON structure\"\n",
        "        else:\n",
        "            return \"Script containing stock data not found\"\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching data: {str(e)}\"\n",
        "    except json.JSONDecodeError:\n",
        "        return \"Error parsing JSON data\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred: {str(e)}\"\n",
        "\n",
        "# Use the function to get AAPL stock volume\n",
        "aapl_volume = scrape_stock_volume('AAPL')\n",
        "print(f\"AAPL Stock Volume: {aapl_volume}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWgt5ZoP5WRG",
        "outputId": "c8993a18-72fa-470f-dabb-c7ed557adb61"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAPL Stock Volume: Script containing stock data not found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-6ebe4929cdd9>:12: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  script = soup.find('script', text=re.compile('root.App.main'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets try an easier website\n",
        "url1 = 'https://forecast.weather.gov/MapClick.php?CityName=Cheney&state=WA&site=OTX&textField1=47.4875&textField2=-117.575&e=0'\n",
        "response1 = requests.get(url1)\n",
        "soup1 = BeautifulSoup(response1.content,'html.parser')\n",
        "#lets get the title\n",
        "Title = soup1.title.string\n",
        "print(f\"Title: {Title}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmvaV434zUne",
        "outputId": "5f921d1c-ae47-489c-91a2-3f1c35cc55ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: National Weather Service\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_humidity(url):\n",
        "  response = requests.get(url)\n",
        "\n",
        "  #create a chain of conditions to perform the test\n",
        "  if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.content, 'html.parser') #parse data\n",
        "    Humidity_element = soup.find('td', string='Humidity') #find the data\n",
        "    if Humidity_element:\n",
        "      Humidity_data = Humidity_element.find_next_sibling('td').text.strip()\n",
        "      return Humidity_data\n",
        "    else:\n",
        "      return \"Humidity information not found\"\n",
        "  else:\n",
        "    return f\"Failed to retrieve the webpage. Status code: {response.status_code}\"\n",
        "\n",
        "url = 'https://forecast.weather.gov/MapClick.php?CityName=Cheney&state=WA&site=OTX&textField1=47.4875&textField2=-117.575&e=0'\n",
        "Humidity = scrape_humidity(url)\n",
        "print(f'current Humidity {Humidity}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2Jb37dQ-brn",
        "outputId": "d752f650-c608-4672-8c3f-5ff3a9602dbd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current Humidity 44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def scrape_dewpoint(url):\n",
        "    # Send a GET request to the webpage\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find the dewpoint information\n",
        "        dewpoint_element = soup.find('td', string='Dewpoint')\n",
        "        if dewpoint_element:\n",
        "            dewpoint = dewpoint_element.find_next_sibling('td').text.strip()\n",
        "            return dewpoint\n",
        "        else:\n",
        "            return \"Dewpoint information not found\"\n",
        "    else:\n",
        "        return f\"Failed to retrieve the webpage. Status code: {response.status_code}\"\n",
        "\n",
        "# URL of the weather page\n",
        "url = \"https://forecast.weather.gov/MapClick.php?CityName=Cheney&state=WA&site=OTX&textField1=47.4875&textField2=-117.575&e=0\"\n",
        "\n",
        "# Scrape the dewpoint\n",
        "dewpoint = scrape_dewpoint(url)\n",
        "print(f\"Current Dewpoint: {dewpoint}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LniGFnsH9Nmu",
        "outputId": "fdd1687c-2fe4-472f-9689-5659dccb3029"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Dewpoint: 32째F (0째C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def get_first_search_result(query):\n",
        "    # Format the query string for a search\n",
        "    query = query.replace(' ', '+')\n",
        "    a_url = f\"https://www.google.com/search?q={query}\"\n",
        "\n",
        "    # Send a GET request to DuckDuckGo\n",
        "    response = requests.get(a_url)\n",
        "    if response.status_code == 200:\n",
        "        # Parse the search result page\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find the first search result link\n",
        "        result = soup.find('a', {'class': 'result__a'})\n",
        "        if result:\n",
        "            return result['href']\n",
        "        else:\n",
        "            return \"No search results found.\"\n",
        "    else:\n",
        "        return f\"Failed to retrieve search results. Status code: {response.status_code}\"\n",
        "\n",
        "# Example usage\n",
        "query = \"National+Weather+Service+cheney\"\n",
        "url = get_first_search_result(query)\n",
        "print(f\"First search result: {url}\")'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "30u3yt91TiTq",
        "outputId": "d1560db1-c347-4a46-82f2-56cd0681a83f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef get_first_search_result(query):\\n    # Format the query string for a search\\n    query = query.replace(\\' \\', \\'+\\')\\n    a_url = f\"https://www.google.com/search?q={query}\"\\n\\n    # Send a GET request to DuckDuckGo\\n    response = requests.get(a_url)\\n    if response.status_code == 200:\\n        # Parse the search result page\\n        soup = BeautifulSoup(response.content, \\'html.parser\\')\\n\\n        # Find the first search result link\\n        result = soup.find(\\'a\\', {\\'class\\': \\'result__a\\'})\\n        if result:\\n            return result[\\'href\\']\\n        else:\\n            return \"No search results found.\"\\n    else:\\n        return f\"Failed to retrieve search results. Status code: {response.status_code}\"\\n\\n# Example usage\\nquery = \"National+Weather+Service+cheney\"\\nurl = get_first_search_result(query)\\nprint(f\"First search result: {url}\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_first_search_result(query):\n",
        "    # Format the query string for a search\n",
        "    query = query.replace(' ', '+')\n",
        "    url = f\"https://www.google.com/search?q={query}\"\n",
        "\n",
        "    # Send a GET request to Google\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Parse the search result page\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find the first search result link\n",
        "        result = soup.find('div', class_='yuRUbf')\n",
        "        if result:\n",
        "            link = result.find('a')\n",
        "            if link:\n",
        "                return link['href']\n",
        "\n",
        "        return \"No search results found.\"\n",
        "    else:\n",
        "        return f\"Failed to retrieve search results. Status code: {response.status_code}\"\n",
        "\n",
        "# Example usage\n",
        "query = \"National Weather Service cheney\"\n",
        "url = get_first_search_result(query)\n",
        "print(f\"First search result: {url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-aroJN2PRMO",
        "outputId": "47f19c0f-9e2a-4695-9242-264bd08d8a32"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First search result: https://forecast.weather.gov/zipcity.php?inputstring=Cheney,WA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_#searching for stuff in a table of data\n",
        "Elements = ['Humidity','Dewpoint', 'Wind Speed', 'Visibility']\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:    # Check if the request was successful\n",
        "# Parse the HTML content\n",
        "\n",
        "  def Data_in_cheney(url):\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    output = []\n",
        "    for i in range(len(Elements)):\n",
        "\n",
        "          element = soup.find('td', string=f'{Elements[i]}')\n",
        "          if element:\n",
        "              data = element.find_next_sibling('td').string.strip()\n",
        "              output.append(data)\n",
        "          else:\n",
        "              return f\"{Elements[i]} information not found\"\n",
        "    return output\n",
        "\n",
        "else:\n",
        "  print( f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
        "\n",
        "# URL of the weather page\n",
        "\n",
        "# Scrape the dewpoint\n",
        "charcacteristc = Data_in_cheney(url)\n",
        "for i in range(len(Elements)):\n",
        "    print(f\"{Elements[i]}: {str(charcacteristc[i])}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_-9kuMWCKeh",
        "outputId": "7bd12ac7-8e67-45dd-ce1e-fa3072cf62fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Humidity: 44%\n",
            "Dewpoint: 32째F (0째C)\n",
            "Wind Speed: E 3 MPH\n",
            "Visibility: NA\n"
          ]
        }
      ]
    }
  ]
}